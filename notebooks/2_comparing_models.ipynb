{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8421c78b",
   "metadata": {},
   "source": [
    "### This notebook is meant to explore and compare models before selecting the one that will be used for the inference API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa1ebf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root to sys.path (Jupyter version)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from src.loaders import load_required_attributes_from_raw\n",
    "from src.column_transformers import TitanicInputTransformer\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fb654bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training provided LinearSVC with GridSearchCV...\n",
      "Training provided RandomForest with GridSearchCV...\n",
      "Training LinearSVC with GridSearchCV...\n",
      "Training RandomForest with GridSearchCV...\n",
      "Training LogisticRegression with GridSearchCV...\n",
      "Training XGBoost with GridSearchCV...\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "CV F1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CV Precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CV Recall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CV Accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Best Params",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "4457f174-fe4c-4e2a-a454-fc2f04661faa",
       "rows": [
        [
         "0",
         "provided LinearSVC",
         "0.722",
         "0.758",
         "0.693",
         "0.796",
         "{}"
        ],
        [
         "1",
         "provided RandomForest",
         "0.768",
         "0.789",
         "0.749",
         "0.826",
         "{}"
        ],
        [
         "2",
         "LinearSVC",
         "0.728",
         "0.805",
         "0.667",
         "0.809",
         "{'clf__C': 0.01, 'clf__dual': False, 'clf__fit_intercept': True, 'clf__loss': 'squared_hinge', 'clf__tol': 0.01}"
        ],
        [
         "3",
         "RandomForest",
         "0.79",
         "0.831",
         "0.754",
         "0.846",
         "{'clf__bootstrap': True, 'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 5, 'clf__n_estimators': 100}"
        ],
        [
         "4",
         "LogisticRegression",
         "0.733",
         "0.796",
         "0.681",
         "0.81",
         "{'clf__C': 0.1, 'clf__penalty': 'l2', 'clf__solver': 'saga'}"
        ],
        [
         "5",
         "XGBoost",
         "0.797",
         "0.849",
         "0.751",
         "0.853",
         "{'clf__colsample_bytree': 0.8, 'clf__gamma': 1, 'clf__learning_rate': 0.2, 'clf__max_depth': 5, 'clf__min_child_weight': 5, 'clf__n_estimators': 200, 'clf__subsample': 0.8}"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV F1</th>\n",
       "      <th>CV Precision</th>\n",
       "      <th>CV Recall</th>\n",
       "      <th>CV Accuracy</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>provided LinearSVC</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.796</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>provided RandomForest</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.826</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.809</td>\n",
       "      <td>{'clf__C': 0.01, 'clf__dual': False, 'clf__fit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.846</td>\n",
       "      <td>{'clf__bootstrap': True, 'clf__max_depth': Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.810</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__penalty': 'l2', 'clf__so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.853</td>\n",
       "      <td>{'clf__colsample_bytree': 0.8, 'clf__gamma': 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  CV F1  CV Precision  CV Recall  CV Accuracy  \\\n",
       "0     provided LinearSVC  0.722         0.758      0.693        0.796   \n",
       "1  provided RandomForest  0.768         0.789      0.749        0.826   \n",
       "2              LinearSVC  0.728         0.805      0.667        0.809   \n",
       "3           RandomForest  0.790         0.831      0.754        0.846   \n",
       "4     LogisticRegression  0.733         0.796      0.681        0.810   \n",
       "5                XGBoost  0.797         0.849      0.751        0.853   \n",
       "\n",
       "                                         Best Params  \n",
       "0                                                 {}  \n",
       "1                                                 {}  \n",
       "2  {'clf__C': 0.01, 'clf__dual': False, 'clf__fit...  \n",
       "3  {'clf__bootstrap': True, 'clf__max_depth': Non...  \n",
       "4  {'clf__C': 0.1, 'clf__penalty': 'l2', 'clf__so...  \n",
       "5  {'clf__colsample_bytree': 0.8, 'clf__gamma': 1...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "# Load and preprocess data\n",
    "X, y = load_required_attributes_from_raw('../data/train.csv')\n",
    "\n",
    "# Specify numeric columns to scale\n",
    "numeric_features = ['Age', 'Fare']\n",
    "numeric_scaler = ColumnTransformer(\n",
    "    transformers=[('num', StandardScaler(), numeric_features)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Define dummy groups and columns to drop\n",
    "dummy_groups = {\n",
    "    'Sex': ['female', 'male'],\n",
    "    'Embarked': ['C', 'Q', 'S'],\n",
    "    'Pclass': ['Class_1', 'Class_2', 'Class_3']\n",
    "}\n",
    "columns_to_drop = [cols[0] for cols in dummy_groups.values()]\n",
    "\n",
    "\n",
    "pipelines = {\n",
    "    'provided LinearSVC': Pipeline([\n",
    "        ('input_transform', TitanicInputTransformer()),\n",
    "        ('scaler', numeric_scaler),\n",
    "        ('clf', LinearSVC(random_state=42))\n",
    "    ]),\n",
    "    'provided RandomForest': Pipeline([\n",
    "        ('input_transform', TitanicInputTransformer()),\n",
    "        ('clf', RandomForestClassifier(random_state=42))\n",
    "    ]),\n",
    "    'LinearSVC': Pipeline([\n",
    "        ('input_transform', TitanicInputTransformer()),\n",
    "        ('scaler', numeric_scaler),\n",
    "        ('clf', LinearSVC(max_iter=10000, random_state=42))\n",
    "    ]),\n",
    "    'RandomForest': Pipeline([\n",
    "        ('input_transform', TitanicInputTransformer()),\n",
    "        ('clf', RandomForestClassifier(random_state=42))\n",
    "    ]),\n",
    "    'LogisticRegression': Pipeline([\n",
    "        ('input_transform', TitanicInputTransformer()),\n",
    "        ('scaler', numeric_scaler),\n",
    "        ('clf', LogisticRegression(max_iter=1000, random_state=42))\n",
    "    ]),\n",
    "    'XGBoost': Pipeline([\n",
    "        ('input_transform', TitanicInputTransformer()),\n",
    "        ('clf', xgb.XGBClassifier(eval_metric='logloss', random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Update param_grids for pipelines (prefix model params with 'clf__')\n",
    "param_grids = {\n",
    "    'provided LinearSVC': {},\n",
    "    'provided RandomForest': {},\n",
    "    'LinearSVC': {\n",
    "        'clf__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'clf__dual': [True, False],\n",
    "        'clf__loss': ['hinge', 'squared_hinge'],\n",
    "        'clf__fit_intercept': [True, False],\n",
    "        'clf__tol': [1e-4, 1e-3, 1e-2]\n",
    "    },\n",
    "    'RandomForest': {\n",
    "    'clf__n_estimators': [100, 200, 300],\n",
    "    'clf__max_depth': [3, 5, 7, 10, None],\n",
    "    'clf__min_samples_split': [2, 5, 10],\n",
    "    'clf__min_samples_leaf': [1, 2, 4],\n",
    "    'clf__max_features': ['sqrt', 'log2'],\n",
    "    'clf__bootstrap': [True, False]\n",
    "    },\n",
    "    'LogisticRegression': [\n",
    "        {'clf__penalty': ['l1'], 'clf__C': [0.01, 0.1, 1, 10], 'clf__solver': ['liblinear']},\n",
    "        {'clf__penalty': ['l2'], 'clf__C': [0.01, 0.1, 1, 10], 'clf__solver': ['liblinear', 'saga', 'lbfgs']},\n",
    "        {'clf__penalty': ['elasticnet'], 'clf__C': [0.01, 0.1, 1, 10], 'clf__solver': ['saga'], 'clf__l1_ratio': [0.0, 0.5, 1.0]},\n",
    "        {'clf__penalty': ['none'], 'clf__solver': ['saga', 'lbfgs']}\n",
    "    ],\n",
    "    'XGBoost': {\n",
    "        'clf__n_estimators': [100, 200],\n",
    "        'clf__max_depth': [3, 5, 7],\n",
    "        'clf__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'clf__subsample': [0.8, 1],\n",
    "        'clf__colsample_bytree': [0.8, 1],\n",
    "        'clf__gamma': [0, 1],\n",
    "        'clf__min_child_weight': [1, 5]\n",
    "    }\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1'\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in pipelines.items():\n",
    "    print(f\"Training {name} with GridSearchCV...\")\n",
    "    grid = GridSearchCV(\n",
    "        model,\n",
    "        param_grids[name],\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        refit='f1',\n",
    "        n_jobs=-1,\n",
    "        return_train_score=True\n",
    "    )\n",
    "    grid.fit(X, y)\n",
    "    best_idx = grid.best_index_\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'CV F1': grid.cv_results_['mean_test_f1'][best_idx],\n",
    "        'CV Precision': grid.cv_results_['mean_test_precision'][best_idx],\n",
    "        'CV Recall': grid.cv_results_['mean_test_recall'][best_idx],\n",
    "        'CV Accuracy': grid.cv_results_['mean_test_accuracy'][best_idx],\n",
    "        'Best Params': grid.best_params_\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).round(3)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f02ebd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "import pickle\n",
    "with open(\"../models/best_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(grid, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e29f67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def save_importances_from_xgboost_model(model, X_train, importances_path):\n",
    "    \"\"\"\n",
    "    Extract and save grouped feature importances from a fitted XGBoost pipeline.\n",
    "\n",
    "    Parameters:\n",
    "    - model: fitted best_estimator_ (Pipeline with input_transform, optional scaler, and XGBClassifier)\n",
    "    - X_train: training data used to fit the input transformer\n",
    "    - importances_path: path to save grouped importances as JSON\n",
    "    \"\"\"\n",
    "\n",
    "    # Unpack pipeline\n",
    "    input_transform = model.named_steps[\"input_transform\"]\n",
    "    scaler = model.named_steps.get(\"scaler\")\n",
    "    clf = model.named_steps[\"clf\"]\n",
    "\n",
    "    # Fit input and scaling transformers\n",
    "    X_transformed = input_transform.fit_transform(X_train)\n",
    "\n",
    "    if scaler is not None:\n",
    "        scaler.fit(X_transformed)\n",
    "\n",
    "        def get_feature_names_from_column_transformer(ct: ColumnTransformer):\n",
    "            feature_names = []\n",
    "            for name, transformer, cols in ct.transformers_:\n",
    "                if transformer in ('drop', None):\n",
    "                    continue\n",
    "                if hasattr(transformer, 'get_feature_names_out'):\n",
    "                    names = transformer.get_feature_names_out(cols)\n",
    "                else:\n",
    "                    names = cols\n",
    "                feature_names.extend(names)\n",
    "            return feature_names\n",
    "\n",
    "        feature_names = get_feature_names_from_column_transformer(scaler)\n",
    "    else:\n",
    "        feature_names = (\n",
    "            X_transformed.columns.tolist()\n",
    "            if isinstance(X_transformed, pd.DataFrame)\n",
    "            else X_train.columns.tolist()\n",
    "        )\n",
    "\n",
    "    # Get importances from XGBoost\n",
    "    importances = clf.feature_importances_\n",
    "\n",
    "    # Map feature names to original user input keys\n",
    "    reverse_mapping = {\n",
    "        'Age': 'Age',\n",
    "        'Fare': 'Fare',\n",
    "        'SibSp': 'SibSp',\n",
    "        'Parch': 'Parch',\n",
    "        'male': 'Sex',\n",
    "        'female': 'Sex',\n",
    "        'Class_1': 'Pclass',\n",
    "        'Class_2': 'Pclass',\n",
    "        'Class_3': 'Pclass',\n",
    "        'C': 'Embarked',\n",
    "        'Q': 'Embarked',\n",
    "        'S': 'Embarked'\n",
    "    }\n",
    "\n",
    "    def map_feature_to_user_key(feature_name):\n",
    "        return reverse_mapping.get(feature_name, feature_name)\n",
    "\n",
    "    grouped_importances = defaultdict(list)\n",
    "    for feat, imp in zip(feature_names, importances):\n",
    "        user_key = map_feature_to_user_key(feat)\n",
    "        grouped_importances[user_key].append(imp)\n",
    "\n",
    "    # Build and export as JSON\n",
    "    df = pd.DataFrame([\n",
    "        {\"User Input Key\": key, \"Total Importance\": round(float(np.sum(imps)), 4)}\n",
    "        for key, imps in grouped_importances.items()\n",
    "    ])\n",
    "\n",
    "    df = df.sort_values(\"Total Importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    df.to_json(importances_path, orient=\"records\", indent=2)\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open(\"../models/best_model.pkl\", \"rb\") as f:\n",
    "    grid=pickle.load(f)\n",
    "X, _ = load_required_attributes_from_raw('../data/train.csv')\n",
    "\n",
    "save_importances_from_xgboost_model(\n",
    "        model=grid.best_estimator_,\n",
    "        X_train=X,\n",
    "        importances_path=\"../models/feature_importance.json\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rappi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
